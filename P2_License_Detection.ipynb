{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IjBBL4s6ssxE"
      },
      "outputs": [],
      "source": [
        "# Set up environment\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5zcjVxZwZIi"
      },
      "outputs": [],
      "source": [
        "# Define directory structure\n",
        "base_dir = \"/content/drive/MyDrive/11_LicensePlateDetection\"\n",
        "os.makedirs(base_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBw_r_--sslt"
      },
      "outputs": [],
      "source": [
        "# Setup Folder Structure\n",
        "\n",
        "import os\n",
        "# Define directory structure\n",
        "base_dir = \"/content/drive/MyDrive/11_LicensePlateDetection\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "folders = [\"frames\", \"annotations\", \"images\", \"labels\", \"yolo_results\", \"runs\"]\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)\n",
        "\n",
        "print(\"Folder structure created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEat_6UHssjC"
      },
      "outputs": [],
      "source": [
        "# Verify Filepaths (via Drive)\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/11_LicensePlateDetection/DomDash.MOV\"\n",
        "output_folder = \"/content/drive/MyDrive/11_LicensePlateDetection/frames\"\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuNy0DICssfG"
      },
      "outputs": [],
      "source": [
        "# Analyze the video\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "video_duration = total_frames / fps\n",
        "frame_duration = 1 / fps\n",
        "\n",
        "# Print video properties\n",
        "print(f\"Frames Per Second (FPS): {fps}\")\n",
        "print(f\"Total Frames: {total_frames}\")\n",
        "print(f\"Video Duration: {video_duration:.2f} seconds\")\n",
        "print(f\"Time per Frame: {frame_duration:.4f} seconds\")\n",
        "\n",
        "cap.release()  # Close video file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_YjyZdkzwmo"
      },
      "outputs": [],
      "source": [
        "# Extract frames\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_rate = 10  # Extract every 10th frame\n",
        "frame_count = 0\n",
        "extracted_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if frame_count % frame_rate == 0:\n",
        "        frame_path = os.path.join(output_folder, f\"frame_{extracted_count}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        extracted_count += 1\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "\n",
        "print(f\"Total Extracted Frames: {extracted_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOMV1rj5zwch"
      },
      "outputs": [],
      "source": [
        "# Get the resolution\n",
        "\n",
        "if extracted_count > 0:\n",
        "    first_frame_path = os.path.join(output_folder, \"frame_0.jpg\")\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    print(f\"Video Resolution: {first_frame.shape[1]}x{first_frame.shape[0]} (Width x Height)\")\n",
        "else:\n",
        "    print(\"Video Resolution: no frames extracted)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIeFcbYrzwQE"
      },
      "outputs": [],
      "source": [
        "# Display the first 5 frames\n",
        "\n",
        "sample_frames = []\n",
        "for i in range(5):\n",
        "    frame_path = os.path.join(output_folder, f\"frame_{i*5}.jpg\")\n",
        "    img = cv2.imread(frame_path)\n",
        "    sample_frames.append(img)\n",
        "\n",
        "# Display first 5 extracted frames\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i, img in enumerate(sample_frames):\n",
        "    axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    axes[i].axis(\"off\")\n",
        "    axes[i].set_title(f\"Frame {i*5}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U33NosyZzwFK"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "\n",
        "# Paths\n",
        "images_path = \"/content/drive/MyDrive/11_LicensePlateDetection/frames\"  # Extracted frames\n",
        "results_path = \"/content/drive/MyDrive/11_LicensePlateDetection/yolo_results\"  # YOLO results\n",
        "os.makedirs(results_path, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Pre-trained YOLO model\n",
        "\n",
        "# Run detection\n",
        "for img in os.listdir(images_path):\n",
        "    image_path = os.path.join(images_path, img)\n",
        "\n",
        "    if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "      try:\n",
        "        results = model.predict(image_path, save=True, conf=0.4, project=results_path)  # Save results in custom folder\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"Skipping non-image file: {img}\")\n",
        "\n",
        "print(f\"YOLOv8 predictions saved in: {results_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VCeEQxurzv5v"
      },
      "outputs": [],
      "source": [
        "# Label frames\n",
        "\n",
        "# Define paths\n",
        "images_folder = \"/content/drive/MyDrive/11_LicensePlateDetection/frames\"  # Path to extracted frames\n",
        "labels_folder = \"/content/drive/MyDrive/11_LicensePlateDetection/annotations\"  # Folder to save YOLO labels\n",
        "os.makedirs(labels_folder, exist_ok=True)\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Run detection on each frame\n",
        "for img_file in os.listdir(images_folder):\n",
        "    if img_file.lower().endswith((\".jpg\")):\n",
        "        img_path = os.path.join(images_folder, img_file)\n",
        "        try:\n",
        "          results = model.predict(img_path, conf=0.3)\n",
        "\n",
        "          # Get image dimensions\n",
        "          img = cv2.imread(img_path)\n",
        "          img_h, img_w, _ = img.shape  # Height, Width\n",
        "\n",
        "          label_txt_path = os.path.join(labels_folder, img_file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\").replace(\".jpeg\",\".txt\"))\n",
        "\n",
        "          # Open label file to write annotations\n",
        "          with open(label_txt_path, \"w\") as label_file:\n",
        "              for r in results:\n",
        "                  for box in r.boxes.xyxy:\n",
        "                      x1, y1, x2, y2 = box.tolist()\n",
        "\n",
        "                      # Convert to YOLO format\n",
        "                      x_center = ((x1 + x2) / 2) / img_w\n",
        "                      y_center = ((y1 + y2) / 2) / img_h\n",
        "                      width = (x2 - x1) / img_w\n",
        "                      height = (y2 - y1) / img_h\n",
        "\n",
        "                      # Write to label file\n",
        "                      label_file.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing {img_path}: {e}\")\n",
        "    else:\n",
        "      print(f\"Skipping non-image file: {img_file}\")\n",
        "print(\"Auto-labeling complete! Check the 'labels/' folder for annotations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdDAsTmRssW6"
      },
      "outputs": [],
      "source": [
        "# Split and Move Images and Labels\n",
        "\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define dataset directories\n",
        "frames_dir = os.path.join(base_dir, \"frames\")\n",
        "annotations_dir = os.path.join(base_dir, \"annotations\")\n",
        "\n",
        "# Define train, val, and test directories\n",
        "train_images_dir = os.path.join(base_dir, 'images/train')\n",
        "train_labels_dir = os.path.join(base_dir, 'labels/train')\n",
        "val_images_dir = os.path.join(base_dir, 'images/val')\n",
        "val_labels_dir = os.path.join(base_dir, 'labels/val')\n",
        "test_images_dir = os.path.join(base_dir, 'images/test')\n",
        "test_labels_dir = os.path.join(base_dir, 'labels/test')\n",
        "\n",
        "# Create directories if they don’t exist\n",
        "for folder in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, test_images_dir, test_labels_dir]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# Get all images from frames directory\n",
        "image_files = [f for f in os.listdir(frames_dir) if f.endswith(\".jpg\")]\n",
        "random.shuffle(image_files)  # Shuffle images for randomness\n",
        "\n",
        "# Define dataset split sizes\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_size = int(len(image_files) * train_ratio)\n",
        "val_size = int(len(image_files) * val_ratio)\n",
        "test_size = len(image_files) - (train_size + val_size)\n",
        "\n",
        "# Assign images to each dataset\n",
        "train_files = image_files[:train_size]\n",
        "val_files = image_files[train_size:train_size + val_size]\n",
        "test_files = image_files[train_size + val_size:]\n",
        "\n",
        "# Function to copy files instead of move\n",
        "def copy_files(file_list, source_dir, dest_images_dir, dest_labels_dir):\n",
        "    for file in file_list:\n",
        "        img_path = os.path.join(source_dir, file)\n",
        "        label_path = os.path.join(annotations_dir, file.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        # Copy image if exists\n",
        "        if os.path.exists(img_path):\n",
        "            shutil.copy(img_path, os.path.join(dest_images_dir, file))\n",
        "\n",
        "        # Copy corresponding label if exists\n",
        "        if os.path.exists(label_path):\n",
        "            shutil.copy(label_path, os.path.join(dest_labels_dir, file.replace(\".jpg\", \".txt\")))\n",
        "\n",
        "# Copy images and labels into their respective folders\n",
        "copy_files(train_files, frames_dir, train_images_dir, train_labels_dir)\n",
        "copy_files(val_files, frames_dir, val_images_dir, val_labels_dir)\n",
        "copy_files(test_files, frames_dir, test_images_dir, test_labels_dir)\n",
        "\n",
        "# Verify the split\n",
        "print(f\"Dataset split complete!\")\n",
        "print(f\"   Train: {len(train_files)} images\")\n",
        "print(f\"   Validation: {len(val_files)} images\")\n",
        "print(f\"   Test: {len(test_files)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a6vh-OY70Puq"
      },
      "outputs": [],
      "source": [
        "# Train Yolo\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train model and save outputs in Google Drive\n",
        "model.train(data=\"/content/drive/MyDrive/11_LicensePlateDetection/data.yaml\", epochs=25, imgsz=640, batch=16,\n",
        "            project=\"/content/drive/MyDrive/11_LicensePlateDetection/runs\", name=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DyzVetQ0Pls"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model Performance\n",
        "\n",
        "# Display training results\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Find the latest training run results\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/11_LicensePlateDetection/runs/train*'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PUYoxSmtJrjy"
      },
      "outputs": [],
      "source": [
        "# Test Model on Test Images\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO('/content/drive/MyDrive/11_LicensePlateDetection/runs/train4/weights/best.pt')\n",
        "\n",
        "# Run prediction\n",
        "results = model.predict(\n",
        "    source='/content/drive/MyDrive/11_LicensePlateDetection/test_image.jpg',  # image path\n",
        "    conf=0.30,        # confidence threshold\n",
        "    save=True,        # save result image\n",
        "    save_txt=True,    # save prediction labels\n",
        "    project='runs/detect',\n",
        "    name='test_on_image',\n",
        "    exist_ok=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GYEo6VYyJrUW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Show the image with bounding boxes\n",
        "display(Image(filename='/content/runs/detect/test_on_image/test_image.jpg'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuQMTrOEw-8U"
      },
      "source": [
        "## Roboflow Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgQNzrT62pvk"
      },
      "outputs": [],
      "source": [
        "# Set up environment\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApiCBIHd1Pir"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"dataset\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "#!curl -L \"x\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "#!rm roboflow.zip # Remove the zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oYsjyOOb20ov"
      },
      "outputs": [],
      "source": [
        "# Train Yolo\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train model and save outputs in Google Drive\n",
        "model.train(data=\"/content/drive/MyDrive/0_Practicum2/dataset/data.yaml\", epochs=25, imgsz=640, batch=16,\n",
        "            project=\"/content/drive/MyDrive/0_Practicum2/dataset/runs\", name=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qwpruHk6yfj"
      },
      "source": [
        "# Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaiJtx7I6P2n"
      },
      "outputs": [],
      "source": [
        "# Display training results\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Find the latest training run results\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/dataset/runs/train'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYtRwNUv7qM5"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "STZQ9fkk_eik"
      },
      "outputs": [],
      "source": [
        "# Continue training\n",
        "\n",
        "# Load best model\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/dataset/runs/train/weights/best.pt\")\n",
        "\n",
        "# Continue training\n",
        "model.train(data=\"/content/drive/MyDrive/0_Practicum2/dataset/data.yaml\",\n",
        "            epochs=75,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            project=\"/content/drive/MyDrive/0_Practicum2/dataset/runs\",\n",
        "            name=\"more_training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEJdjXfNCB1m"
      },
      "outputs": [],
      "source": [
        "# Display training results\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Find the latest training run results\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/dataset/runs/more_training'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x9cSkTDCRvc"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxfXHMxtFKHl"
      },
      "outputs": [],
      "source": [
        "# Run validation\n",
        "original_metrics = model_one.val(data=\"/content/drive/MyDrive/0_Practicum2/dataset/data.yaml\")\n",
        "continued_metrics = model_two.val(data=\"/content/drive/MyDrive/0_Practicum2/dataset/data.yaml\")\n",
        "\n",
        "# Access metrics via results_dict\n",
        "orig = original_metrics.results_dict\n",
        "cont = continued_metrics.results_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MdoXSdvGGzj"
      },
      "outputs": [],
      "source": [
        "# Compare models\n",
        "\n",
        "print(f\"{'Metric':<20} {'1st Model':<20} {'2nd Model'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'mAP@0.50':<20} {orig['metrics/mAP50(B)']:<20.4f} {cont['metrics/mAP50(B)']:.4f}\")\n",
        "print(f\"{'mAP@0.50:0.95':<20} {orig['metrics/mAP50-95(B)']:<20.4f} {cont['metrics/mAP50-95(B)']:.4f}\")\n",
        "print(f\"{'Precision':<20} {orig['metrics/precision(B)']:<20.4f} {cont['metrics/precision(B)']:.4f}\")\n",
        "print(f\"{'Recall':<20} {orig['metrics/recall(B)']:<20.4f} {cont['metrics/recall(B)']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxVRuJaKGqHD"
      },
      "outputs": [],
      "source": [
        "# Box Plot\n",
        "\n",
        "# Replace these with actual values from model.val().results_dict\n",
        "original_metrics = {\n",
        "    'mAP@0.50': 0.7131,\n",
        "    'mAP@0.50:0.95': 0.3999,\n",
        "    'Precision': 0.8977,\n",
        "    'Recall': 0.6115\n",
        "}\n",
        "\n",
        "continued_metrics = {\n",
        "    'mAP@0.50': 0.8100,\n",
        "    'mAP@0.50:0.95': 0.4838,\n",
        "    'Precision': 0.8546,\n",
        "    'Recall': 0.7116\n",
        "}\n",
        "\n",
        "# Set up data\n",
        "metrics_names = list(original_metrics.keys())\n",
        "original_values = list(original_metrics.values())\n",
        "continued_values = list(continued_metrics.values())\n",
        "\n",
        "x = range(len(metrics_names))\n",
        "bar_width = 0.35\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, original_values, width=bar_width, label='1st Model', color='blue')\n",
        "plt.bar([i + bar_width for i in x], continued_values, width=bar_width, label='2nd Model', color='orange')\n",
        "\n",
        "# Add labels, title, etc.\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Performance')\n",
        "plt.xticks([i + bar_width / 2 for i in x], metrics_names)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pretkzNLlFp"
      },
      "source": [
        "Next Steps:\n",
        "\n",
        "*   Finish labeling images\n",
        "*   Train model with larger dataset\n",
        "*   Implement OCR\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LdGGccNRAj6"
      },
      "source": [
        "# Complete - Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eDnKuVTRXHN"
      },
      "outputs": [],
      "source": [
        "# Set up environment\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch_fzSJdUqYl"
      },
      "source": [
        "# Data Import in Yolov8 Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuCGCALrULG3"
      },
      "outputs": [],
      "source": [
        "# Data Import (1691 images)\n",
        "\n",
        "# Define paths\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"customdata_yolov8\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "#!curl -L \"xxx\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "!rm roboflow.zip # Remove the zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_utd5ZeVoEe"
      },
      "source": [
        "## Yolov8n Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qc4Ch_4UVXXM"
      },
      "outputs": [],
      "source": [
        "# Train Yolo\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Train model and save outputs in Google Drive\n",
        "model.train(data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\", epochs=100, imgsz=640, batch=16,\n",
        "            project=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs\", name=\"v8n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5zgnCDufMeM"
      },
      "source": [
        "# Evaluate Yolov8n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ty8MGjffWuo"
      },
      "outputs": [],
      "source": [
        "# Display training results\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Find the latest training run results\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWU4JGF7a_Ll"
      },
      "outputs": [],
      "source": [
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v8Ch_Obfosf"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na8AU61OjH_R"
      },
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6ldbR_regj8K"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n/weights/best.pt\")\n",
        "\n",
        "# Fine-tune settings\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    lr0=0.001,   # lower learning rate\n",
        "    optimizer=\"SGD\",\n",
        "    augment=True,\n",
        "    project=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs\",\n",
        "    name=\"v8n_finetuned\",\n",
        "    resume=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbvOEMYWuKB5"
      },
      "source": [
        "# Evaluate Yolov8n - Refined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IQQhjFHKh1c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n_finetuned'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Sje-ggJa0B5"
      },
      "outputs": [],
      "source": [
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta9nV7tSh0Kh"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spkzaJsGwkOb"
      },
      "source": [
        "Recall is still under .60, mAP plateaued, classification is bouncing (taking on a lot noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVppWi32xP2H"
      },
      "source": [
        "# Yolov8m Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-EKvgH0gxcPQ"
      },
      "outputs": [],
      "source": [
        "# Train Yolo\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "# Train model and save outputs in Google Drive\n",
        "model.train(data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\", epochs=100, imgsz=640, batch=16,\n",
        "            project=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs\", name=\"v8m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LG6rJokCzlp"
      },
      "source": [
        "# Evaluate Yolov8m Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pzkhGblCroz"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhZ8-lskapn8"
      },
      "outputs": [],
      "source": [
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9RC4qF2E1P8"
      },
      "outputs": [],
      "source": [
        "metrics = model.val(data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\", verbose=True, plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oP_THzWMXro"
      },
      "outputs": [],
      "source": [
        "# Check number of val images\n",
        "val_images = \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/valid/images\"\n",
        "val_labels = \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/valid/labels\"\n",
        "\n",
        "print(\"Number of val images:\", len(os.listdir(val_images)))\n",
        "print(\"Number of val labels:\", len(os.listdir(val_labels)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca-wYczsdITM"
      },
      "source": [
        "# Refine Yolov8m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "834ieQL6dMaJ"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m/weights/best.pt\")\n",
        "\n",
        "# Continue training for 100 more epochs\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\",\n",
        "    epochs=100,\n",
        "    patience=25,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    optimizer=\"SGD\",\n",
        "    augment=True,\n",
        "    project=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs\",\n",
        "    name=\"v8m_refined\",\n",
        "    resume=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SpC_iRk_bHo"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m_refined'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOnl3SOcAr8i"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m_refined/weights/best.pt\") # Assuming \"best.pt\" is your best model\n",
        "\n",
        "# Run validation to get metrics\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\")\n",
        "\n",
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTCWm088FbgT"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N67hIGfSButh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Metrics for all four model runs\n",
        "data = {\n",
        "    \"Model\": [\n",
        "        \"YOLOv8n_v1\",\n",
        "        \"YOLOv8n_refined\",\n",
        "        \"YOLOv8m_v1\",\n",
        "        \"YOLOv8m_refined\"\n",
        "    ],\n",
        "    \"Precision\": [0.81, 0.84, 0.87, 0.84],\n",
        "    \"Recall\": [0.50, 0.56, 0.72, 0.59],\n",
        "    \"mAP@0.50\": [0.65, 0.66, 0.88, 0.70],\n",
        "    \"mAP@0.50:0.95\": [0.27, 0.33, 0.60, 0.36]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Bar positions and width\n",
        "x = np.arange(len(df[\"Model\"]))\n",
        "width = 0.2\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot each metric\n",
        "ax.bar(x - 1.5*width, df[\"Precision\"], width, label='Precision')\n",
        "ax.bar(x - 0.5*width, df[\"Recall\"], width, label='Recall')\n",
        "ax.bar(x + 0.5*width, df[\"mAP@0.50\"], width, label='mAP@0.50')\n",
        "ax.bar(x + 1.5*width, df[\"mAP@0.50:0.95\"], width, label='mAP@0.50:0.95')\n",
        "\n",
        "# Labels, title, and legend\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('YOLO Model Performance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(df[\"Model\"], rotation=15)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.legend(loc='upper left')\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-tJZLlbGITN"
      },
      "source": [
        "# Yolo 11 Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Tf7Tg6GTc0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"yolov11\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "#!curl -L \"xxx\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "!rm roboflow.zip # Remove the zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbVvQjMtJZQO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Download the YOLOv11 weights file\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov11.pt -P /content/drive/MyDrive/0_Practicum2/yolov11 # Download and place in your project directory\n",
        "\n",
        "# Update the path to the YOLOv11 weights file in your code\n",
        "model_path = \"/content/drive/MyDrive/0_Practicum2/yolov11\"\n",
        "model = YOLO(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-7giO73z3Dg"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tXmm-m6r0lJa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z4JFEKSJ02Qo"
      },
      "outputs": [],
      "source": [
        "!pip list | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMnULHr20rvk"
      },
      "outputs": [],
      "source": [
        "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSue4hQI4Zd0"
      },
      "outputs": [],
      "source": [
        "# Set working directory\n",
        "project_dir = \"/content/drive/MyDrive/0_Practicum2/yolov11\"\n",
        "os.chdir(project_dir)\n",
        "\n",
        "# Confirm current directory\n",
        "print(\"Current directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j13blXmB4wZw"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=train model=yolo11s.pt data=\"/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml\", epochs=50 imgsz=640 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "divBdZJNBFfy"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bRFAMQ2aCPZp"
      },
      "outputs": [],
      "source": [
        "# Load the trained YOLO model\n",
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2/weights/best.pt')  # Path to your best.pt file\n",
        "\n",
        "# Run validation to get metrics\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml\")  # Path to your data.yaml\n",
        "\n",
        "# Now you can print the metrics\n",
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3CpFypLXEGmZ"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2/weights/best.pt')\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml',\n",
        "    epochs=20,\n",
        "    lr0=0.0005,\n",
        "    patience=5,\n",
        "    resume=False\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q7cCYlDkHhE9"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train3'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOMmir9BJM6e"
      },
      "source": [
        "# Rollback to Previous Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tsUQk1nkI1ie"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO3kbPMAJr30"
      },
      "source": [
        "# Yolov11m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yofBbc4vM7J3"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov11m.pt -P /content/drive/MyDrive/0_Practicum2/yolov11/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nKPetUBtJrTs"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11m.pt')\n",
        "\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml',\n",
        "    epochs=100,\n",
        "    imgsz=800,\n",
        "    batch=16,\n",
        "    patience=10,\n",
        "    project='runs',\n",
        "    name='yolov11m',\n",
        "    lr0=0.001\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-2c_zhVahKYm"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XevCM4XXi4-R"
      },
      "outputs": [],
      "source": [
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VQktaUG6kxyi"
      },
      "outputs": [],
      "source": [
        "metrics = model.val(\n",
        "    data='data.yaml',\n",
        "    conf=0.25,\n",
        "    augment=True,\n",
        "    iou=0.6\n",
        ")\n",
        "print(metrics.box)  # Precision, Recall, mAP50, mAP50-95\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6StwazhlKeN"
      },
      "outputs": [],
      "source": [
        "print(f\"mAP@0.5:        {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-MrAX53iwlB"
      },
      "source": [
        "# Compare all models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PUQ9nMuj8-k"
      },
      "source": [
        "Run validation on each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FpugWvN1i2_2"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Define model names and paths\n",
        "model_paths = {\n",
        "    \"YOLOv8n_v1\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n/weights/best.pt\",\n",
        "    \"YOLOv8n_refined\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n_finetuned/weights/best.pt\",\n",
        "    \"YOLOv8m_v1\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m/weights/best.pt\",\n",
        "    \"YOLOv8m_refined\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m_refined/weights/best.pt\",\n",
        "    \"YOLOv11s\": \"/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2/weights/best.pt\",\n",
        "    \"YOLOv11m\": \"/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m/weights/best.pt\"\n",
        "}\n",
        "\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for name, path in model_paths.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    model = YOLO(path)\n",
        "    metrics = model.val(data='data.yaml', split='val', verbose=False)\n",
        "\n",
        "    results_dict[name] = {\n",
        "        'precision': metrics.box.mp,\n",
        "        'recall': metrics.box.mr,\n",
        "        'mAP@0.50': metrics.box.map50,\n",
        "        'mAP@0.50:0.95': metrics.box.map\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kLGmyi5kBso"
      },
      "source": [
        "Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqbLAD2VkIFn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract metric names and model names\n",
        "metrics = ['precision', 'recall', 'mAP@0.50', 'mAP@0.50:0.95']\n",
        "model_names = list(results_dict.keys())\n",
        "\n",
        "# Gather data\n",
        "data = {metric: [results_dict[model][metric] for model in model_names] for metric in metrics}\n",
        "\n",
        "# Plotting\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.2\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(x + i * width, data[metric], width, label=metric)\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('YOLO Model Performance Comparison')\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels(model_names, rotation=15)\n",
        "ax.set_ylim(0, 1.0)\n",
        "ax.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeGcjES8rR4J"
      },
      "source": [
        "Evaluate Models closer to training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5Hxh0pwrWut"
      },
      "outputs": [],
      "source": [
        "# Define model names and paths\n",
        "model_paths = {\n",
        "    \"YOLOv8n_v1\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n/weights/best.pt\",\n",
        "    \"YOLOv8n_refined\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8n_finetuned/weights/best.pt\",\n",
        "    \"YOLOv8m_v1\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m/weights/best.pt\",\n",
        "    \"YOLOv8m_refined\": \"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8m_refined/weights/best.pt\",\n",
        "    \"YOLOv11s\": \"/content/drive/MyDrive/0_Practicum2/yolov11/runs/detect/train2/weights/best.pt\",\n",
        "    \"YOLOv11m\": \"/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m/weights/best.pt\"\n",
        "}\n",
        "\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "for name, path in model_paths.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    model = YOLO(path)\n",
        "    metrics = model.val(data='data.yaml', split='val', conf=0.15, iou=0.6, augment=True, verbose=False)\n",
        "\n",
        "    results_dict[name] = {\n",
        "        'precision': metrics.box.mp,\n",
        "        'recall': metrics.box.mr,\n",
        "        'mAP@0.50': metrics.box.map50,\n",
        "        'mAP@0.50:0.95': metrics.box.map\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJymqqm7s2-Z"
      },
      "outputs": [],
      "source": [
        "# Extract metric names and model names\n",
        "metrics = ['precision', 'recall', 'mAP@0.50', 'mAP@0.50:0.95']\n",
        "model_names = list(results_dict.keys())\n",
        "\n",
        "# Gather data\n",
        "data = {metric: [results_dict[model][metric] for model in model_names] for metric in metrics}\n",
        "\n",
        "# Plotting\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.2\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(x + i * width, data[metric], width, label=metric)\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('YOLO Model Performance Comparison')\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels(model_names, rotation=15)\n",
        "ax.set_ylim(0, 1.0)\n",
        "ax.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2WWPZyB6yTP"
      },
      "source": [
        "# Run Inference on Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCzAE44Z6lOB"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m/weights/best.pt')\n",
        "\n",
        "# Inference on all images in a folder\n",
        "results = model.predict(\n",
        "    source='/content/drive/MyDrive/11_LicensePlateDetection/test_image.jpg',  # Folder with your test JPG/PNG files\n",
        "    conf=0.25,                      # Confidence threshold (adjust if needed)\n",
        "    save=True,                      # Saves results to /runs/detect/predict\n",
        "    show=True                       # Displays results inline in notebook\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1j1PQ0GUDOy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the trained YOLOv11m model\n",
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m/weights/best.pt')\n",
        "\n",
        "# Run inference and save to custom folder\n",
        "results = model.predict(\n",
        "    source='/content/drive/MyDrive/11_LicensePlateDetection/test_image.jpg',\n",
        "    conf=0.25,\n",
        "    save=True,\n",
        "    save_dir='/content/drive/MyDrive/0_Practicum2/Model_Images',\n",
        "    show=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB0nZOpEVo9P"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Define the path to the saved YOLO result\n",
        "predict_dir = '/content/runs/detect/predict5'\n",
        "\n",
        "# List files in the directory\n",
        "files = os.listdir(predict_dir)\n",
        "\n",
        "# Find the first image (e.g., .jpg or .png)\n",
        "image_file = next((f for f in files if f.lower().endswith(('.jpg', '.png'))), None)\n",
        "\n",
        "# Load and display the image\n",
        "if image_file:\n",
        "    image_path = os.path.join(predict_dir, image_file)\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"YOLOv11m Detection Result\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No image file found in:\", predict_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhAyXabh3wzY"
      },
      "source": [
        "# Modifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zVuc6Wvr4X07"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/yolov11/yolo11m.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=800,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    optimizer=\"SGD\",\n",
        "    augment=True,\n",
        "    patience=20,\n",
        "    project=\"runs\",\n",
        "    name=\"yolov11m_cleaned\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h4iD4i6fZDJ"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/runs/yolov11m_cleaned'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgXBkiAog53x"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CidpGglxW90"
      },
      "source": [
        "# Final Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8LlUFBKxmPr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"11_yolo\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "!curl -L \"https://app.roboflow.com/ds/xhi0wmXd2s?key=G0Hg6KlAI8\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "!rm roboflow.zip # Remove the zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygi376g1z-FY"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "W1U3EgYSz2TT"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/yolov11/yolo11m.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/0_Practicum2/11_yolo/data.yaml\",\n",
        "    epochs=150,\n",
        "    imgsz=800,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    optimizer=\"SGD\",\n",
        "    augment=True,\n",
        "    patience=20,\n",
        "    project=\"runs\",\n",
        "    name=\"11yolov_last\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfbMuFUkYwdf"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtftUFdwYjnx"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = YOLO(\"/content/runs/11yolov_last/weights/best.pt\")\n",
        "\n",
        "# Evaluate model\n",
        "metrics = model.val(data=\"/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml\", split='val')\n",
        "\n",
        "\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDT72OiDZQ7W"
      },
      "outputs": [],
      "source": [
        "train_results_path = max(glob.glob('/content/runs/11yolov_last'), key=os.path.getctime)\n",
        "\n",
        "# Load training performance image\n",
        "performance_img = os.path.join(train_results_path, \"results.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTYvm0zeZ4l6"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "performance_img = os.path.join(train_results_path, \"confusion_matrix_normalized.png\")\n",
        "img = cv2.imread(performance_img)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_mrsDqfZ8Vw"
      },
      "source": [
        "# Validation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbSFF3a2aXjG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename='/content/runs/detect/val/confusion_matrix_normalized.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgUTW59EahL5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load your best trained model\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m_cleaned/weights/best.pt\")\n",
        "\n",
        "# 2. Set your test image path\n",
        "test_image_path = \"/content/drive/MyDrive/0_Practicum2/Nissan_Images/BasePic.jpg\"\n",
        "\n",
        "# 3. Run inference\n",
        "results = model.predict(source=test_image_path, conf=0.05, save=False, show=False, verbose=False)[0]\n",
        "\n",
        "# 4. Load and prepare the image\n",
        "image = cv2.imread(test_image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 5. Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    confidence = score * 100  # convert to percentage\n",
        "    label = f\"{confidence:.1f}%\"  # e.g., \"97.5%\"\n",
        "\n",
        "    # Draw rectangle\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Put confidence text\n",
        "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "# 6. Show the final image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv11m Detection with Confidence\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTub6q77FGXL"
      },
      "source": [
        "# April Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKuUKusGFDAk"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"April_Run\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "#!curl -L \"xxx\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "!rm roboflow.zip # Remove the zip file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T_KF8BlhFN9E"
      },
      "outputs": [],
      "source": [
        "# Train Yolo\n",
        "\n",
        "# Load model\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "# Train model and save outputs in Google Drive\n",
        "model.train(data=\"/content/drive/MyDrive/0_Practicum2/dataset/data.yaml\", epochs=150, imgsz=640, batch=16, patience=20,\n",
        "            project=\"/content/drive/MyDrive/0_Practicum2/April_Run/runs\", name=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouGIFJx2SZU2"
      },
      "outputs": [],
      "source": [
        "results = model.val(data=\"/content/drive/MyDrive/0_Practicum2/April_Run/data.yaml\", split='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXfE9WsYXWlW"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/yolov11/runs/yolov11m_cleaned/weights/best.pt\")\n",
        "\n",
        "# Load and convert the image\n",
        "image_path = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/BasePic.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run detection\n",
        "results = model(image_path, conf=0.01, verbose=False)[0]\n",
        "\n",
        "# Check if any boxes were detected\n",
        "if results.boxes is None or len(results.boxes.xyxy) == 0:\n",
        "    print(\"No license plates detected.\")\n",
        "else:\n",
        "    print(f\"{len(results.boxes.xyxy)} object(s) detected.\")\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for box in results.boxes.xyxy.cpu().numpy():\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    # Show image with bounding boxes\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"YOLOv11 Detection Test\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nskLa0asYfMy"
      },
      "outputs": [],
      "source": [
        "val_results = model.val(data='/content/drive/MyDrive/0_Practicum2/yolov11/data.yaml')\n",
        "print(f\"mAP@0.5: {val_results.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {val_results.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eRih7QP9Y70B"
      },
      "outputs": [],
      "source": [
        "# Load a pretrained general YOLOv8 model\n",
        "pretrained_model = YOLO('yolov8m.pt')  # or yolov8m.pt\n",
        "\n",
        "# Predict on your image\n",
        "pretrained_model.predict(source='/content/drive/MyDrive/0_Practicum2/Nissan_Images/BasePic.jpg', conf=0.25, show=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-bECEB1uZq5t"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = YOLO('yolov8m.pt')\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=800,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    optimizer=\"SGD\",\n",
        "    augment=True,\n",
        "    patience=25,\n",
        "    project=\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs\",\n",
        "    name=\"v8_Retrain_April\",\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXTDl6YrOm8N"
      },
      "source": [
        "# Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "197TnmlnPDa5"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqu7zcXpOmN1"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt')\n",
        "results = model.val(data='/content/drive/MyDrive/0_Practicum2/customdata_yolov8/data.yaml')\n",
        "print(f\"mAP@0.5: {results.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {results.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MWHLMsSz0Pz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your best-trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/11_LicensePlateDetection/test_image.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.25, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    confidence = score * 100\n",
        "    label = f\"{confidence:.1f}%\"\n",
        "\n",
        "    cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "    cv2.putText(image_rgb, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h287btQW5s2Y"
      },
      "outputs": [],
      "source": [
        "# Load your best-trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/11_LicensePlateDetection/test_image.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.25, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    confidence = score * 100\n",
        "    label = f\"{confidence:.1f}%\"\n",
        "\n",
        "    # Draw rectangle around the plate\n",
        "    cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    # Text background box\n",
        "    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)\n",
        "    cv2.rectangle(image_rgb, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "    # Put readable confidence text over it\n",
        "    cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq83wPUp6C6q"
      },
      "outputs": [],
      "source": [
        "# Load your best-trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/10FT.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.15, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    confidence = score * 100\n",
        "    label = f\"{confidence:.1f}%\"\n",
        "\n",
        "    # Draw rectangle around the plate\n",
        "    cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    # Text background box\n",
        "    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)\n",
        "    cv2.rectangle(image_rgb, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "    # Put readable confidence text over it\n",
        "    cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5AjiBmV7wn8"
      },
      "source": [
        "# Detection on Directory Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fDA5uHG7iN2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Load trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Directory with test images\n",
        "image_dir = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/'\n",
        "image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
        "\n",
        "# Loop through each image\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image_path, conf=0.15, verbose=False)[0]\n",
        "\n",
        "    # Draw bounding boxes and large confidence text\n",
        "    for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        confidence = score * 100\n",
        "        label = f\"{confidence:.1f}%\"\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "        # Background for text\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)\n",
        "        cv2.rectangle(image_rgb, (x1, y1 - text_height - 12), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "        # Overlay confidence label\n",
        "        cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 0), 4)\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"YOLOv8 Inference - {os.path.basename(image_path)}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDKuTMqr94ub"
      },
      "outputs": [],
      "source": [
        "# Load your best-trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/11_LicensePlateDetection/test_image2.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.15, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        confidence = score * 100\n",
        "        label = f\"{confidence:.1f}%\"\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "        # Background for text\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)\n",
        "        cv2.rectangle(image_rgb, (x1, y1 - text_height - 12), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "        # Overlay confidence label\n",
        "        cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 0), 4)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeB1V7goOW-2"
      },
      "source": [
        "# New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6r1SVfCOdGp"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "project_name = \"30_April_Run\"\n",
        "drive_path = \"/content/drive/MyDrive/0_Practicum2\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Download and unzip dataset directly to Drive\n",
        "#!curl -L \"xxx\" > roboflow.zip\n",
        "!unzip -q roboflow.zip -d \"{os.path.join(drive_path, project_name)}\" # Unzip directly to drive path\n",
        "!rm roboflow.zip # Remove the zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HrWKTODORFC-"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = YOLO(\"/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/last.pt\")\n",
        "\n",
        "# Start a new training run instead of resuming\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/0_Practicum2/30_April_Run/data.yaml',\n",
        "    epochs=30,\n",
        "    imgsz=1024,\n",
        "    batch=8,\n",
        "    resume=False,\n",
        "    name='v8_New_data_Model',\n",
        "    project='/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lZQBfw5LY96r"
      },
      "outputs": [],
      "source": [
        "model.val(data='/content/drive/MyDrive/0_Practicum2/30_April_Run/data.yaml')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uDX9fggZgvL"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_New_data_Model/weights/best.pt')\n",
        "results = model.val(data='/content/drive/MyDrive/0_Practicum2/30_April_Run/data.yaml')\n",
        "print(f\"mAP@0.5: {results.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {results.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILK5AC9VZ6SH"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8mRRV5BaSdW"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_Retrain_April/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/11_LicensePlateDetection/test_image2.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.15, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        confidence = score * 100\n",
        "        label = f\"{confidence:.1f}%\"\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "        # Background for text\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)\n",
        "        cv2.rectangle(image_rgb, (x1, y1 - text_height - 12), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "        # Overlay confidence label\n",
        "        cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 0), 4)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhJFBZF4Z86y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Load trained model\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_New_data_Model/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Directory with test images\n",
        "image_dir = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/'\n",
        "image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
        "\n",
        "# Loop through each image\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image_path, conf=0.35, verbose=False)[0]\n",
        "\n",
        "    # Draw bounding boxes and large confidence text\n",
        "    for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        confidence = score * 100\n",
        "        label = f\"{confidence:.1f}%\"\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "        # Background for text\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)\n",
        "        cv2.rectangle(image_rgb, (x1, y1 - text_height - 12), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "        # Overlay confidence label\n",
        "        cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 0), 4)\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"YOLOv8 Inference - {os.path.basename(image_path)}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfhoXl0pcLqp"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_New_data_Model/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/BasePic.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.45, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        confidence = score * 100\n",
        "        label = f\"{confidence:.1f}%\"\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "        # Background for text\n",
        "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)\n",
        "        cv2.rectangle(image_rgb, (x1, y1 - text_height - 12), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "        # Overlay confidence label\n",
        "        cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 0), 4)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXErDaQmdEx9"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_path = '/content/drive/MyDrive/0_Practicum2/customdata_yolov8/runs/v8_New_data_Model/weights/best.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Path to test image\n",
        "image_path = '/content/drive/MyDrive/0_Practicum2/Nissan_Images/10FT.jpg'\n",
        "\n",
        "# Read and convert image\n",
        "image = cv2.imread(image_path)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path, conf=0.45, verbose=False)[0]\n",
        "\n",
        "# Draw bounding boxes and confidence scores\n",
        "for box, score in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy()):\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    confidence = score * 100\n",
        "    label = f\"{confidence:.1f}%\"\n",
        "\n",
        "    # Draw rectangle around the plate\n",
        "    cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "    # Text background box\n",
        "    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)\n",
        "    cv2.rectangle(image_rgb, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 255, 0), -1)\n",
        "\n",
        "    # Put readable confidence text over it\n",
        "    cv2.putText(image_rgb, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
        "\n",
        "# Show result\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"YOLOv8 Inference with best.pt\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a-MrAX53iwlB",
        "JQLLoynMj9MA",
        "Sn4NvBv4ZSW9",
        "i9xt2vUkbPeI"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}